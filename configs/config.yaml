settings:
  #################   DATASET CONFIG   ###################

  project_name: "vqa"    
  train_imgs: "/content/data/train2014"
  val_imgs: "/content/data/val2014"
  train_anns: "/content/data/VQAv2/v2_coco_train2014_annotations.json"
  val_anns: "/content/data/VQAv2/v2_coco_val2014_annotations.json"
  train_question: "/content/data/VQAv2/v2_OpenEnded_mscoco_train2014_questions.json"
  val_question: "/content/data/VQAv2/v2_OpenEnded_mscoco_val2014_questions.json"
  class_path: "/content/data/VQAv2/3klabel.txt"
  npy_dir:

  #################   TRAINING CONFIG   ###################
  
  model_name:  'catr' 
  language:    'bert-base-uncased'
  image_size:   [224,224]               # 224 or 384 (pretrained vit support these only)
  keep_ratio:   False

  gpu_devices: '0'                     # supports multi-gpus
  num_epochs: 100
  batch_size: 128
  num_workers: 2

  # learning rate policy
  lr_policy:
    name: "adam"                         #[adam|sgd]
    lr: 0.0005                            #[adam: 1e-3 | sgd: 1e-2]
    momentum: 0.9
    weight_decay: 0.000001

  lr_scheduler:
    name: "cosine2"                      #[plateau | cosine | 1cycle-yolo | 1cycle]
                                        # if need to specify more scheduler arguments, do it here

  # gradient accumulation
  mixed_precision: False                # whether to use nvidia apex
  total_accumulate_steps: 0           # step * batch_size, not use if equal 0